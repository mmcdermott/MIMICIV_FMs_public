{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8ec3491",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%load_ext memory_profiler\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import rootutils\n",
    "\n",
    "root = rootutils.setup_root(os.path.abspath(\"\"), dotenv=True, pythonpath=True, cwd=False)\n",
    "sys.path.append(os.environ[\"EVENT_STREAM_PATH\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "823423b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import polars as pl\n",
    "from EventStream.data.dataset_polars import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9335ee6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "COHORT_NAME = \"MIMIC_IV/ESD_new_schema_08-22-23-1\"\n",
    "PROJECT_DIR = Path(os.environ[\"PROJECT_DIR\"])\n",
    "DATA_DIR = PROJECT_DIR / \"data\" / COHORT_NAME\n",
    "assert DATA_DIR.is_dir()\n",
    "\n",
    "ESD = Dataset.load(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d078a045",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "from EventStream.data.types import DataModality, TemporalityType, NumericDataModalitySubtype\n",
    "\n",
    "def _HF_template_melt_df(\n",
    "    self, source_df: pl.DataFrame, id_cols: Sequence[str], measures: list[str],\n",
    "    default_struct_fields: dict[str, pl.DataType] | None = None,\n",
    ") -> pl.Expr:\n",
    "    \"\"\"Re-formats `source_df` into the desired deep-learning output format.\"\"\"\n",
    "    struct_fields_by_m = {}\n",
    "    total_vocab_size = self.vocabulary_config.total_vocab_size\n",
    "    idx_dt = self.get_smallest_valid_int_type(total_vocab_size)\n",
    "    \n",
    "    if default_struct_fields is None: default_struct_fields = {}\n",
    "    else: default_struct_fields = {**default_struct_fields}\n",
    "\n",
    "    for m in measures:\n",
    "        if m == \"event_type\":\n",
    "            cfg = None\n",
    "            modality = DataModality.SINGLE_LABEL_CLASSIFICATION\n",
    "        else:\n",
    "            cfg = self.measurement_configs[m]\n",
    "            modality = cfg.modality\n",
    "\n",
    "        if modality != DataModality.UNIVARIATE_REGRESSION:\n",
    "            idx_value_expr = (\n",
    "                pl.when(pl.col(m).is_not_null())\n",
    "                .then(f\"{m}/\" + pl.col(m).cast(pl.Utf8))\n",
    "                .otherwise(pl.lit(None, dtype=pl.Utf8))\n",
    "            )\n",
    "        else:\n",
    "            idx_value_expr = (\n",
    "                pl.when(pl.col(m).is_not_null())\n",
    "                .then(pl.lit(f\"{m}\", dtype=pl.Utf8))\n",
    "                .otherwise(pl.lit(None, dtype=pl.Utf8))\n",
    "            )\n",
    "            \n",
    "        idx_value_expr = idx_value_expr.alias(\"code\")\n",
    "\n",
    "        if (modality == DataModality.UNIVARIATE_REGRESSION) and (\n",
    "            cfg.measurement_metadata.value_type\n",
    "            in (NumericDataModalitySubtype.FLOAT, NumericDataModalitySubtype.INTEGER)\n",
    "        ):\n",
    "            val_expr = pl.col(m).cast(pl.Float32)\n",
    "        elif modality == DataModality.MULTIVARIATE_REGRESSION:\n",
    "            val_expr = pl.col(cfg.values_column).cast(pl.Float32)\n",
    "        else:\n",
    "            val_expr = pl.lit(None, dtype=pl.Float32)\n",
    "            \n",
    "        struct_fields = {**default_struct_fields}\n",
    "        \n",
    "        struct_fields.update({\n",
    "            'code': idx_value_expr,\n",
    "            'numeric_value': val_expr.alias(\"numeric_value\"),\n",
    "        })\n",
    "                \n",
    "        if cfg is not None and cfg.modifiers is not None:\n",
    "            for mod_col in cfg.modifiers:\n",
    "                mod_col_expr = pl.col(mod_col)\n",
    "                if source_df[mod_col].dtype == pl.Categorical:\n",
    "                    mod_col_expr = mod_col_expr.cast(pl.Utf8)\n",
    "                    \n",
    "                struct_fields[mod_col] = mod_col_expr.alias(mod_col)\n",
    "        \n",
    "        struct_fields_by_m[m] = struct_fields\n",
    "        \n",
    "    struct_field_order = ['code', 'numeric_value', 'text_value', 'datetime_value']\n",
    "    struct_field_order += sorted([k for k in default_struct_fields.keys() if k not in struct_field_order])\n",
    "    struct_exprs = [\n",
    "        pl.struct([fields[k] for k in struct_field_order]).alias(m)\n",
    "        for m, fields in struct_fields_by_m.items()\n",
    "    ]\n",
    "    \n",
    "    return (\n",
    "        source_df.select(*id_cols, *struct_exprs)\n",
    "        .melt(\n",
    "            id_vars=id_cols,\n",
    "            value_vars=measures,\n",
    "            variable_name=\"_to_drop\",\n",
    "            value_name=\"measurement\",\n",
    "        )\n",
    "        .filter(pl.col(\"measurement\").struct.field(\"code\").is_not_null())\n",
    "        .select(*id_cols, \"measurement\")\n",
    "    )\n",
    "\n",
    "\n",
    "def build_HF_representation(\n",
    "    self, subject_ids: list[int] | None = None, do_sort_outputs: bool = False\n",
    ") -> pl.DataFrame:\n",
    "    # Identify the measurements sourced from each dataframe:\n",
    "    subject_measures, event_measures, dynamic_measures = [], [\"event_type\"], []\n",
    "    default_struct_fields = {\n",
    "        'text_value': pl.lit(None, dtype=pl.Utf8).alias('text_value'),\n",
    "        'datetime_value': pl.lit(None, dtype=pl.Datetime).alias(\"datetime_value\"),\n",
    "    }\n",
    "    for m in self.unified_measurements_vocab[1:]:\n",
    "        cfg = self.measurement_configs[m]\n",
    "        match cfg.temporality:\n",
    "            case TemporalityType.STATIC:\n",
    "                source_df = self.subjects_df\n",
    "                subject_measures.append(m)\n",
    "            case TemporalityType.FUNCTIONAL_TIME_DEPENDENT:\n",
    "                source_df = self.events_df\n",
    "                event_measures.append(m)\n",
    "            case TemporalityType.DYNAMIC:\n",
    "                source_df = self.dynamic_measurements_df\n",
    "                dynamic_measures.append(m)\n",
    "            case _:\n",
    "                raise ValueError(f\"Unknown temporality type {cfg.temporality} for {m}\")\n",
    "        \n",
    "        if cfg.modifiers is None: continue\n",
    "            \n",
    "        for mod_col in cfg.modifiers:\n",
    "            if mod_col not in source_df:\n",
    "                raise IndexError(f\"mod_col {mod_col} missing!\")\n",
    "            \n",
    "            out_dt = source_df[mod_col].dtype\n",
    "            if out_dt == pl.Categorical:\n",
    "                out_dt = pl.Utf8\n",
    "            default_struct_fields[mod_col] = pl.lit(None, dtype=out_dt).alias(mod_col)\n",
    "\n",
    "    # 1. Process subject data into the right format.\n",
    "    if subject_ids:\n",
    "        subjects_df = self._filter_col_inclusion(self.subjects_df, {\"subject_id\": subject_ids})\n",
    "    else:\n",
    "        subjects_df = self.subjects_df\n",
    "        \n",
    "    static_data = (\n",
    "        _HF_template_melt_df(\n",
    "            self, subjects_df, [\"subject_id\"], subject_measures,\n",
    "            default_struct_fields=default_struct_fields\n",
    "        )\n",
    "        .groupby(\"subject_id\")\n",
    "        .agg(pl.col(\"measurement\").alias(\"static_measurements\"))\n",
    "    )\n",
    "\n",
    "    # 2. Process event data into the right format.\n",
    "    if subject_ids:\n",
    "        events_df = self._filter_col_inclusion(self.events_df, {\"subject_id\": subject_ids})\n",
    "        event_ids = list(events_df[\"event_id\"])\n",
    "    else:\n",
    "        events_df = self.events_df\n",
    "        event_ids = None\n",
    "    event_data = _HF_template_melt_df(\n",
    "        self, events_df, [\"subject_id\", \"timestamp\", \"event_id\"], event_measures,\n",
    "        default_struct_fields=default_struct_fields\n",
    "    )\n",
    "\n",
    "    # 3. Process measurement data into the right base format:\n",
    "    if event_ids:\n",
    "        dynamic_measurements_df = self._filter_col_inclusion(\n",
    "            self.dynamic_measurements_df, {\"event_id\": event_ids}\n",
    "        )\n",
    "    else:\n",
    "        dynamic_measurements_df = self.dynamic_measurements_df\n",
    "\n",
    "    dynamic_ids = [\"event_id\", \"measurement_id\"] if do_sort_outputs else [\"event_id\"]\n",
    "    dynamic_data = _HF_template_melt_df(\n",
    "        self, dynamic_measurements_df, dynamic_ids, dynamic_measures,\n",
    "        default_struct_fields=default_struct_fields\n",
    "    )\n",
    "\n",
    "    if do_sort_outputs:\n",
    "        dynamic_data = dynamic_data.sort(\"event_id\", \"measurement_id\")\n",
    "\n",
    "    # 4. Join dynamic and event data.\n",
    "\n",
    "    event_data = pl.concat([event_data, dynamic_data], how=\"diagonal\")\n",
    "    event_data = (\n",
    "        event_data.groupby(\"event_id\")\n",
    "        .agg(\n",
    "            pl.col('subject_id').drop_nulls().first(),\n",
    "            pl.col('timestamp').drop_nulls().first(),\n",
    "            pl.col(\"measurement\").alias(\"measurements\")\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.struct([\n",
    "                pl.col(\"timestamp\").alias(\"time\"),\n",
    "                pl.col(\"measurements\").alias(\"measurements\")\n",
    "            ]).alias(\"event\")\n",
    "        )\n",
    "        .sort(\"subject_id\", \"timestamp\")\n",
    "        .groupby(\"subject_id\")\n",
    "        .agg(pl.col(\"event\").alias(\"events\"))\n",
    "    )\n",
    "\n",
    "    out = static_data.join(event_data, on=\"subject_id\", how=\"outer\")\n",
    "    if do_sort_outputs:\n",
    "        out = out.sort(\"subject_id\")\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6b61aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "measurement = pa.struct([\n",
    "    ('code', pa.string()),\n",
    "    ('numeric_value', pa.float32()),\n",
    "    ('text_value', pa.string()),\n",
    "    ('datetime_value', pa.timestamp('us')),\n",
    "])\n",
    "\n",
    "\n",
    "event = pa.struct([\n",
    "    ('time', pa.timestamp('us')),\n",
    "    ('measurements', pa.list_(measurement))\n",
    "])\n",
    "\n",
    "\n",
    "schema = pa.schema([\n",
    "    ('subject_id', pa.int64()),\n",
    "    ('static_measurements', pa.list_(measurement)),\n",
    "    ('events', pa.list_(event)), # Require ordered by time\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d9f8b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e14e134d1cd4f74b9bbc72d71655e95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dynamic_measurements from /n/data1/hms/dbmi/zaklab/RAMMS/data/MIMIC_IV/ESD_new_schema_08-22-23-1/dynamic_measurements_df.parquet...\n",
      "Loading subjects from /n/data1/hms/dbmi/zaklab/RAMMS/data/MIMIC_IV/ESD_new_schema_08-22-23-1/subjects_df.parquet...\n"
     ]
    }
   ],
   "source": [
    "import math, numpy as np\n",
    "import pyarrow.parquet\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "for sp, subjs in tqdm(list(ESD.split_subjects.items())):\n",
    "    n_chunks = int(math.ceil(len(subjs) / 20))\n",
    "    for i, subjs_chunk in enumerate(np.array_split(list(subjs), n_chunks)):\n",
    "        df = build_HF_representation(ESD, do_sort_outputs=True, subject_ids=list(subjs_chunk))\n",
    "        arr_table = df.to_arrow().cast(schema)\n",
    "        fp = ESD.config.save_dir / \"HF_Dataset\" / sp / f\"{i}.parquet\"\n",
    "        fp.parent.mkdir(exist_ok=True, parents=True)\n",
    "        pyarrow.parquet.write_table(arr_table, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23928fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.scan_parquet(ESD.config.save_dir / \"HF_Dataset\" / \"*/*.parquet\")\n",
    "print(\"In raw form:\")\n",
    "display(df.head(2).collect())\n",
    "print(\"Exploded out:\")\n",
    "display(\n",
    "    df\n",
    "    .head(1)\n",
    "    .explode('events')\n",
    "    .unnest('events')\n",
    "    .explode('measurements')\n",
    "    .unnest('measurements')\n",
    "    .head(2)\n",
    "    .collect()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
